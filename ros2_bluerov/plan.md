# Plan d'Action : D√©tection de Cage avec Filtre Spatial et Transform√©e de Hough

## üéØ Objectif Global
Ajouter un syst√®me de d√©tection robuste de la cage en combinant :
1. **Filtre spatial gaussien** centr√© sur la position track√©e pour isoler la cage
2. **Transform√©e de Hough** pour d√©tecter les lignes de la cage
3. **Algorithme de d√©tection de rectangle** pour identifier la forme de la cage
4. **Affichage en temps r√©el** du rectangle d√©tect√©

---

## üìê Architecture Actuelle

### Flux de donn√©es existant
```
sonar_node/sonar_mock 
  ‚Üí /docking/sonar/raw (Frame)
    ‚Üí traitement_polar_node
      ‚Üí /docking/sonar/polar_filtered (Frame)
        ‚Üí traitement_cartesian_node
          ‚Üí /docking/sonar/cartesian_filtered (FrameCartesian)
            ‚Üí csrt_tracker_node
              ‚Üí /docking/tracking/tracked_object (TrackedObject)
            ‚Üí hough_lines_node
              ‚Üí /docking/tracking/detected_lines (DetectedLines)
            ‚Üí sonar_viewer (affichage)
```

### Messages existants
- **TrackedObject** : position (center_x, center_y en m), dimensions (width, height), confiance
- **DetectedLines** : lignes d√©tect√©es (rhos, thetas, points, confidences)
- **FrameCartesian** : image cart√©sienne + m√©tadonn√©es (resolution, max_range, origin_x/y)

---

## üìã Plan D√©taill√© par √âtapes

### ‚úÖ **√âTAPE 0 : Pr√©paration et V√©rification de l'Existant**
**Objectif** : S'assurer que le pipeline actuel fonctionne correctement

#### 0.1 - Tester le pipeline complet
- [x] Lancer `ros2 launch bringup user_pipeline.launch.py` (mock)
- [x] V√©rifier que le sonar_viewer s'affiche correctement
- [x] V√©rifier que le tracker publie sur `/docking/tracking/tracked_object`
- [x] V√©rifier que hough_lines publie sur `/docking/tracking/detected_lines`

#### 0.2 - Visualiser les topics actuels
```bash
ros2 topic echo /docking/tracking/tracked_object
ros2 topic echo /docking/tracking/detected_lines
```

**Crit√®res de succ√®s** :
- ‚úì Sonar_viewer affiche l'image cart√©sienne
- ‚úì Les topics publient des donn√©es valides
- ‚úì Pas d'erreurs dans les logs

---

### ‚úÖ **√âTAPE 1 : Ajout du Filtre Spatial Gaussien dans traitement_cartesian_node**
**Objectif** : Filtrer l'image pour ne garder que la zone autour de la cage track√©e

#### 1.1 - Cr√©er un nouveau message pour le filtre spatial (OPTIONNEL)
Si n√©cessaire, cr√©er `CageFilter.msg` dans `docking_msgs/msg/` :
```msg
# CageFilter.msg - Param√®tres du filtre spatial
float32 center_x      # Centre du filtre (m)
float32 center_y      # Centre du filtre (m)
float32 sigma         # √âcart-type du gaussien (m)
float32 radius        # Rayon d'effet (m)
bool is_active        # Filtre actif ou non
```

**D√âCISION** : On va directement s'abonner √† `TrackedObject` plut√¥t que cr√©er un nouveau message.

#### 1.2 - Modifier `traitement_cartesian_node.py`

**Modifications √† apporter** :

```python
# Nouveaux param√®tres
self.declare_parameter('enable_spatial_filter', True)
self.declare_parameter('spatial_filter_radius', 2.0)  # Rayon en m√®tres
self.declare_parameter('spatial_filter_sigma', 0.8)   # √âcart-type gaussien (m)
self.declare_parameter('spatial_filter_smoothness', 0.3)  # Transition progressive

# Nouvelle subscription
self.tracked_object_sub = self.create_subscription(
    TrackedObject,
    '/docking/tracking/tracked_object',
    self.tracked_object_callback,
    10
)

# Variable d'√©tat
self.last_tracked_position = None  # (center_x, center_y) en m√®tres
```

**Nouvelle m√©thode** :
```python
def apply_spatial_gaussian_filter(self, img: np.ndarray, frame_msg: FrameCartesian) -> np.ndarray:
    """
    Applique un filtre gaussien spatial centr√© sur la position track√©e.
    Att√©nue progressivement les intensit√©s au-del√† du rayon sp√©cifi√©.
    """
    if not self.get_parameter('enable_spatial_filter').value:
        return img
    
    if self.last_tracked_position is None:
        return img  # Pas de position track√©e, pas de filtrage
    
    center_x_m, center_y_m = self.last_tracked_position
    radius_m = float(self.get_parameter('spatial_filter_radius').value)
    sigma_m = float(self.get_parameter('spatial_filter_sigma').value)
    
    # Cr√©er une grille de coordonn√©es en m√®tres
    height, width = img.shape
    resolution = frame_msg.resolution
    
    # Coordonn√©es de chaque pixel en m√®tres (relatif au ROV)
    # x_m[i,j] = (j - origin_x) * resolution
    # y_m[i,j] = (height - i) * resolution
    
    j_indices = np.arange(width)
    i_indices = np.arange(height)
    j_grid, i_grid = np.meshgrid(j_indices, i_indices)
    
    x_grid_m = (j_grid - frame_msg.origin_x) * resolution
    y_grid_m = (height - i_grid) * resolution
    
    # Distance au centre track√©
    dist_m = np.sqrt((x_grid_m - center_x_m)**2 + (y_grid_m - center_y_m)**2)
    
    # Masque gaussien (1.0 au centre, d√©cro√Æt progressivement)
    # Plus sigma est petit, plus la transition est abrupte
    mask = np.exp(-(dist_m**2) / (2 * sigma_m**2))
    
    # Appliquer le masque (multiplication √©l√©ment par √©l√©ment)
    filtered_img = (img.astype(np.float32) * mask).astype(np.uint8)
    
    return filtered_img
```

**Modification de `frame_callback`** :
Appliquer le filtre spatial **apr√®s** la conversion cart√©sienne mais **avant** les autres filtres.

#### 1.3 - Tester le filtre spatial

**Test** :
```bash
# Terminal 1
ros2 launch bringup user_pipeline.launch.py

# Terminal 2 - V√©rifier que le filtre s'applique
ros2 param set /traitement_cartesian_node enable_spatial_filter true
ros2 param set /traitement_cartesian_node spatial_filter_radius 2.5

# Terminal 3 - Initialiser le tracker
# Cliquer dans sonar_viewer avec Ctrl+Clic sur la cage
```

**Crit√®res de succ√®s** :
- ‚úì Quand le tracker est actif, seule la zone autour de la cage reste visible
- ‚úì La transition est progressive (pas de bord dur)
- ‚úì L'intensit√© d√©cro√Æt graduellement avec la distance

#### 1.4 - Ajustement des param√®tres
Tester diff√©rentes valeurs pour trouver le bon compromis :
- `spatial_filter_radius` : 1.5m, 2.0m, 2.5m
- `spatial_filter_sigma` : 0.5m, 0.8m, 1.0m

---

### ‚úÖ **√âTAPE 2 : Am√©lioration de la D√©tection Hough**
**Objectif** : Optimiser la d√©tection de lignes pour la cage

#### 2.1 - Am√©liorer le preprocessing dans `traitement_cartesian_node`

Avant Hough, l'image doit √™tre binaire ou avec des contours nets.

**Ajouter dans `traitement_cartesian_node.py`** :
```python
# Nouveau param√®tre
self.declare_parameter('cart_enable_morphology', True)
self.declare_parameter('cart_morphology_kernel_size', 3)
self.declare_parameter('cart_morphology_iterations', 2)

def apply_morphology_operations(self, img: np.ndarray) -> np.ndarray:
    """Applique des op√©rations morphologiques pour nettoyer l'image."""
    if not self.get_parameter('cart_enable_morphology').value:
        return img
    
    if cv2 is None:
        return img
    
    kernel_size = int(self.get_parameter('cart_morphology_kernel_size').value)
    iterations = int(self.get_parameter('cart_morphology_iterations').value)
    
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    
    # Closing : fermer les petits trous
    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=iterations)
    
    # Opening : supprimer les petits bruits
    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, iterations=1)
    
    return img
```

#### 2.2 - Tester la d√©tection Hough am√©lior√©e

```bash
# Activer Canny + Morphologie
ros2 param set /traitement_cartesian_node cart_enable_canny true
ros2 param set /traitement_cartesian_node cart_enable_morphology true
ros2 param set /traitement_cartesian_node cart_canny_threshold1 50
ros2 param set /traitement_cartesian_node cart_canny_threshold2 150

# Ajuster Hough
ros2 param set /hough_lines_node threshold 30
ros2 param set /hough_lines_node min_line_length 50
ros2 param set /hough_lines_node num_lines 10
```

**Crit√®res de succ√®s** :
- ‚úì Hough d√©tecte au moins 4 lignes (2 verticales pour les poteaux, 2 horizontales pour le haut/bas)
- ‚úì Les lignes sont stables d'une frame √† l'autre
- ‚úì Peu de fausses d√©tections

---

### ‚úÖ **√âTAPE 3 : Cr√©ation d'un N≈ìud de D√©tection de Rectangle**
**Objectif** : Combiner les lignes Hough pour d√©tecter un rectangle

#### 3.1 - Cr√©er un nouveau message `DetectedRectangle.msg`

**Fichier** : `ros2_bluerov/src/docking_msgs/msg/DetectedRectangle.msg`
```msg
# DetectedRectangle.msg - Rectangle d√©tect√© repr√©sentant la cage

std_msgs/Header header

# Validit√© de la d√©tection
bool is_valid

# Position du centre (en m√®tres, rep√®re ROV)
float32 center_x
float32 center_y

# Dimensions (en m√®tres)
float32 width
float32 height

# Orientation (angle en radians, 0 = vertical)
float32 angle

# Coordonn√©es des 4 coins (en m√®tres, dans le sens horaire depuis coin sup√©rieur gauche)
float32[] corners_x  # 4 √©l√©ments
float32[] corners_y  # 4 √©l√©ments

# Confiance de la d√©tection (0.0 - 1.0)
float32 confidence

# Lignes utilis√©es pour la d√©tection (indices dans DetectedLines)
int32[] line_indices
```

#### 3.2 - Cr√©er le n≈ìud `rectangle_detector_node.py`

**Fichier** : `ros2_bluerov/src/tracking/tracking/rectangle_detector_node.py`

**Structure** :
```python
"""
N≈ìud de d√©tection de rectangle √† partir des lignes Hough.
Combine les lignes d√©tect√©es pour identifier un rectangle correspondant √† la cage.
"""

import numpy as np
import rclpy
from rclpy.node import Node
from docking_msgs.msg import DetectedLines, DetectedRectangle, TrackedObject


class RectangleDetectorNode(Node):
    """D√©tecte un rectangle (cage) √† partir des lignes Hough."""
    
    def __init__(self):
        super().__init__('rectangle_detector_node')
        
        # Param√®tres
        self.declare_parameter('enable_detection', True)
        self.declare_parameter('expected_cage_width', 1.0)  # m
        self.declare_parameter('expected_cage_height', 1.5)  # m
        self.declare_parameter('width_tolerance', 0.3)  # ¬±30%
        self.declare_parameter('height_tolerance', 0.3)
        self.declare_parameter('angle_tolerance', 15.0)  # degr√©s
        self.declare_parameter('min_lines_required', 4)
        self.declare_parameter('use_tracked_position', True)  # Utiliser la position du tracker
        
        # Subscriptions
        self.lines_sub = self.create_subscription(
            DetectedLines,
            '/docking/tracking/detected_lines',
            self.lines_callback,
            10
        )
        
        self.tracked_sub = self.create_subscription(
            TrackedObject,
            '/docking/tracking/tracked_object',
            self.tracked_callback,
            10
        )
        
        # Publisher
        self.rectangle_pub = self.create_publisher(
            DetectedRectangle,
            '/docking/tracking/detected_rectangle',
            10
        )
        
        # √âtat
        self.last_tracked_position = None
        self.last_lines = None
        
        self.get_logger().info('Rectangle Detector node d√©marr√©')
    
    def tracked_callback(self, msg: TrackedObject):
        """M√©morise la derni√®re position track√©e."""
        if msg.is_tracking:
            self.last_tracked_position = (msg.center_x, msg.center_y)
    
    def lines_callback(self, msg: DetectedLines):
        """D√©tecte un rectangle √† partir des lignes."""
        if not self.get_parameter('enable_detection').value:
            return
        
        if not msg.is_valid or msg.num_lines < self.get_parameter('min_lines_required').value:
            self.publish_invalid_rectangle(msg.header)
            return
        
        # Extraire les lignes
        lines = []
        for i in range(msg.num_lines):
            line = {
                'rho': msg.rhos[i],
                'theta': msg.thetas[i],
                'x1': msg.x1_points[i],
                'y1': msg.y1_points[i],
                'x2': msg.x2_points[i],
                'y2': msg.y2_points[i],
                'confidence': msg.confidences[i] if msg.confidences else 1.0,
                'index': i
            }
            lines.append(line)
        
        # D√©tecter le rectangle
        rectangle = self.detect_rectangle(lines, msg.header)
        
        # Publier
        self.rectangle_pub.publish(rectangle)
    
    def detect_rectangle(self, lines, header) -> DetectedRectangle:
        """
        Algorithme de d√©tection de rectangle :
        1. Classifier les lignes en verticales/horizontales
        2. Trouver 2 lignes verticales (poteaux) + 2 horizontales (haut/bas)
        3. Calculer les intersections pour obtenir les 4 coins
        4. V√©rifier que les dimensions correspondent √† la cage
        """
        # √Ä impl√©menter (voir d√©tails ci-dessous)
        pass
    
    def classify_lines(self, lines):
        """S√©pare les lignes en verticales et horizontales."""
        vertical_lines = []
        horizontal_lines = []
        
        angle_tol = np.deg2rad(self.get_parameter('angle_tolerance').value)
        
        for line in lines:
            theta = line['theta']
            
            # Vertical : theta proche de 0 ou œÄ
            if abs(theta) < angle_tol or abs(theta - np.pi) < angle_tol:
                vertical_lines.append(line)
            # Horizontal : theta proche de œÄ/2
            elif abs(theta - np.pi/2) < angle_tol:
                horizontal_lines.append(line)
        
        return vertical_lines, horizontal_lines
    
    def find_best_rectangle(self, vertical_lines, horizontal_lines):
        """Trouve la meilleure combinaison de 4 lignes formant un rectangle."""
        # Parcourir toutes les combinaisons possibles
        # Pour chaque paire de verticales et paire d'horizontales :
        #   - Calculer les 4 intersections
        #   - Mesurer largeur et hauteur
        #   - Comparer aux dimensions attendues
        #   - Calculer un score
        # Retourner la meilleure combinaison
        pass
```

**Algorithme d√©taill√© de d√©tection** :

```python
def find_best_rectangle(self, vertical_lines, horizontal_lines):
    """Trouve la meilleure combinaison de lignes formant un rectangle."""
    if len(vertical_lines) < 2 or len(horizontal_lines) < 2:
        return None
    
    expected_width = float(self.get_parameter('expected_cage_width').value)
    expected_height = float(self.get_parameter('expected_cage_height').value)
    width_tol = float(self.get_parameter('width_tolerance').value)
    height_tol = float(self.get_parameter('height_tolerance').value)
    
    best_score = -1
    best_rectangle = None
    
    # Essayer toutes les combinaisons de 2 verticales et 2 horizontales
    for i in range(len(vertical_lines)):
        for j in range(i+1, len(vertical_lines)):
            v1, v2 = vertical_lines[i], vertical_lines[j]
            
            for k in range(len(horizontal_lines)):
                for l in range(k+1, len(horizontal_lines)):
                    h1, h2 = horizontal_lines[k], horizontal_lines[l]
                    
                    # Calculer les 4 intersections
                    corners = self.compute_corners(v1, v2, h1, h2)
                    if corners is None:
                        continue
                    
                    # Calculer dimensions
                    width = abs(corners[1][0] - corners[0][0])
                    height = abs(corners[0][1] - corners[3][1])
                    
                    # V√©rifier que les dimensions correspondent
                    width_error = abs(width - expected_width) / expected_width
                    height_error = abs(height - expected_height) / expected_height
                    
                    if width_error > width_tol or height_error > height_tol:
                        continue  # Dimensions trop diff√©rentes
                    
                    # Calculer un score (bas√© sur erreur + confiances des lignes)
                    dimension_score = 1.0 - (width_error + height_error) / 2.0
                    confidence_score = (v1['confidence'] + v2['confidence'] + 
                                      h1['confidence'] + h2['confidence']) / 4.0
                    
                    score = 0.6 * dimension_score + 0.4 * confidence_score
                    
                    # Si on utilise la position track√©e, privil√©gier les rectangles proches
                    if self.get_parameter('use_tracked_position').value and self.last_tracked_position:
                        center_x = sum(c[0] for c in corners) / 4
                        center_y = sum(c[1] for c in corners) / 4
                        dist_to_tracked = np.sqrt(
                            (center_x - self.last_tracked_position[0])**2 +
                            (center_y - self.last_tracked_position[1])**2
                        )
                        proximity_score = np.exp(-dist_to_tracked / 1.0)
                        score = 0.5 * score + 0.5 * proximity_score
                    
                    if score > best_score:
                        best_score = score
                        best_rectangle = {
                            'corners': corners,
                            'width': width,
                            'height': height,
                            'lines': [v1, v2, h1, h2],
                            'score': score
                        }
    
    return best_rectangle

def compute_corners(self, v1, v2, h1, h2):
    """Calcule les 4 coins form√©s par 2 lignes verticales et 2 horizontales."""
    # Intersection de 2 lignes d√©finies par (rho, theta)
    corners = []
    
    for v_line in [v1, v2]:
        for h_line in [h1, h2]:
            corner = self.line_intersection(v_line, h_line)
            if corner is not None:
                corners.append(corner)
    
    if len(corners) != 4:
        return None
    
    # Trier les coins dans le sens horaire (top-left, top-right, bottom-right, bottom-left)
    corners = self.sort_corners_clockwise(corners)
    
    return corners

def line_intersection(self, line1, line2):
    """Calcule l'intersection de 2 lignes d√©finies par (rho, theta)."""
    rho1, theta1 = line1['rho'], line1['theta']
    rho2, theta2 = line2['theta'], line2['theta']
    
    # Syst√®me d'√©quations :
    # x * cos(theta1) + y * sin(theta1) = rho1
    # x * cos(theta2) + y * sin(theta2) = rho2
    
    A = np.array([
        [np.cos(theta1), np.sin(theta1)],
        [np.cos(theta2), np.sin(theta2)]
    ])
    b = np.array([rho1, rho2])
    
    try:
        point = np.linalg.solve(A, b)
        return (float(point[0]), float(point[1]))
    except np.linalg.LinAlgError:
        return None  # Lignes parall√®les

def sort_corners_clockwise(self, corners):
    """Trie les 4 coins dans le sens horaire."""
    # Calculer le centre
    cx = sum(c[0] for c in corners) / 4
    cy = sum(c[1] for c in corners) / 4
    
    # Calculer l'angle de chaque coin par rapport au centre
    def angle_from_center(corner):
        return np.arctan2(corner[1] - cy, corner[0] - cx)
    
    sorted_corners = sorted(corners, key=angle_from_center)
    
    return sorted_corners
```

#### 3.3 - Int√©grer le nouveau n≈ìud

**Modifier** `ros2_bluerov/src/tracking/setup.py` :
```python
entry_points={
    'console_scripts': [
        'blob_tracker_node = tracking.blob_tracker_node:main',
        'csrt_tracker_node = tracking.csrt_tracker_node:main',
        'hough_lines_node = tracking.hough_lines_node:main',
        'rectangle_detector_node = tracking.rectangle_detector_node:main',  # NOUVEAU
    ],
},
```

**Modifier** `CMakeLists.txt` (si n√©cessaire pour le nouveau message).

#### 3.4 - Compiler et tester

```bash
cd ~/Desktop/Docking_guerledan/ros2_bluerov
colcon build --packages-select docking_msgs tracking
source install/setup.bash

# Lancer le nouveau n≈ìud
ros2 run tracking rectangle_detector_node

# √âcouter les rectangles d√©tect√©s
ros2 topic echo /docking/tracking/detected_rectangle
```

**Crit√®res de succ√®s** :
- ‚úì Le n≈ìud d√©marre sans erreur
- ‚úì Il d√©tecte un rectangle quand la cage est visible
- ‚úì Les dimensions sont coh√©rentes avec la cage (¬±30%)
- ‚úì La position correspond √† la zone track√©e

---

### ‚úÖ **√âTAPE 4 : Affichage du Rectangle dans sonar_viewer**
**Objectif** : Visualiser le rectangle d√©tect√© en temps r√©el

#### 4.1 - Modifier `ros_node.py` dans affichage

**Fichier** : `ros2_bluerov/src/affichage/affichage/app/core/ros_node.py`

```python
from docking_msgs.msg import DetectedRectangle  # AJOUTER

# Dans __init__
self.rectangle_sub = self.create_subscription(
    DetectedRectangle,
    '/docking/tracking/detected_rectangle',
    self.rectangle_callback,
    10
)

def rectangle_callback(self, msg):
    """Transmet le rectangle d√©tect√© au signal Qt."""
    self.signals.new_detected_rectangle.emit(msg)
```

#### 4.2 - Modifier `signals.py`

**Fichier** : `ros2_bluerov/src/affichage/affichage/app/core/signals.py`

```python
new_detected_rectangle = pyqtSignal(object)  # AJOUTER
```

#### 4.3 - Modifier `sonar_display.py` pour dessiner le rectangle

**Fichier** : `ros2_bluerov/src/affichage/affichage/app/widgets/sonar_display.py`

```python
class SonarCartesianWidget(pg.GraphicsLayoutWidget):
    def __init__(self, ...):
        # ... code existant ...
        
        # Nouvel overlay pour le rectangle
        self.rectangle_item = None
    
    def set_detected_rectangle(self, rect_msg):
        """Affiche le rectangle d√©tect√©."""
        if not rect_msg.is_valid:
            if self.rectangle_item is not None:
                self.viewbox.removeItem(self.rectangle_item)
                self.rectangle_item = None
            return
        
        # Extraire les coins (en m√®tres)
        corners_x = rect_msg.corners_x
        corners_y = rect_msg.corners_y
        
        # Convertir en coordonn√©es de l'image (pixels dans l'affichage pyqtgraph)
        # pyqtgraph utilise un syst√®me o√π x=lateral, y=frontal
        
        # Cr√©er un polygon
        points = []
        for i in range(4):
            x_m = corners_x[i]
            y_m = corners_y[i]
            # Convertir en coordonn√©es image (d√©pend de la r√©solution et origine)
            # √Ä adapter selon votre syst√®me de coordonn√©es
            points.append((x_m, y_m))
        
        # Fermer le polygon
        points.append(points[0])
        
        # Supprimer l'ancien rectangle
        if self.rectangle_item is not None:
            self.viewbox.removeItem(self.rectangle_item)
        
        # Cr√©er le nouveau
        self.rectangle_item = pg.PlotDataItem(
            [p[0] for p in points],
            [p[1] for p in points],
            pen=pg.mkPen('r', width=3),  # Rouge, √©paisseur 3
            name='Cage d√©tect√©e'
        )
        self.viewbox.addItem(self.rectangle_item)
```

#### 4.4 - Connecter le signal dans `main_window.py`

**Fichier** : `ros2_bluerov/src/affichage/affichage/app/main_window.py`

```python
# Dans __init__
self.ros_signals.new_detected_rectangle.connect(
    self.sonar_cartesian_widget.set_detected_rectangle
)
```

#### 4.5 - Tester l'affichage

```bash
ros2 launch bringup user_pipeline.launch.py

# Le rectangle rouge devrait s'afficher sur la cage d√©tect√©e
```

**Crit√®res de succ√®s** :
- ‚úì Un rectangle rouge appara√Æt autour de la cage
- ‚úì Le rectangle suit la cage si elle bouge
- ‚úì Le rectangle dispara√Æt si la d√©tection √©choue

---

### ‚úÖ **√âTAPE 5 : Mise √† jour des Launch Files**
**Objectif** : Int√©grer le nouveau n≈ìud dans les pipelines

#### 5.1 - Modifier `user_pipeline.launch.py`

```python
rectangle_detector = Node(
    package='tracking',
    executable='rectangle_detector_node',
    name='rectangle_detector_node',
    parameters=[{
        'enable_detection': True,
        'expected_cage_width': 1.0,
        'expected_cage_height': 1.5,
        'use_tracked_position': True,
    }],
    output='screen'
)

return LaunchDescription([
    sonar_mock,
    traitement,
    csrt_tracker,
    hough_lines_node,  # V√©rifier qu'il est pr√©sent
    rectangle_detector,  # NOUVEAU
    sonar_viewer,
    localisation,
])
```

#### 5.2 - Modifier `sonar_pipeline.launch.py` et `complete_pipeline.launch.py`

Ajouter de m√™me le n≈ìud `rectangle_detector`.

---

### ‚úÖ **√âTAPE 6 : Tests d'Int√©gration Complets**
**Objectif** : Valider le syst√®me complet

#### 6.1 - Test avec mock

```bash
ros2 launch bringup user_pipeline.launch.py

# 1. V√©rifier que la cage s'affiche
# 2. Ctrl+Clic sur la cage pour initialiser le tracker
# 3. Attendre que le tracker soit stable
# 4. V√©rifier que le filtre spatial s'applique
# 5. V√©rifier que Hough d√©tecte des lignes
# 6. V√©rifier que le rectangle appara√Æt
```

#### 6.2 - Test avec rosbag

```bash
ros2 launch bringup rosbag_pipeline.launch.py

# M√™me s√©quence de tests
```

#### 6.3 - Test avec sonar r√©el (si disponible)

```bash
ros2 launch bringup sonar_pipeline.launch.py

# Valider en conditions r√©elles
```

#### 6.4 - Tests de robustesse

- [ ] Mouvement lat√©ral du ROV
- [ ] Rotation du ROV
- [ ] Approche de la cage
- [ ] √âloignement de la cage
- [ ] Occlusions partielles
- [ ] Bruit sonar

---

### ‚úÖ **√âTAPE 7 : Tuning et Optimisation**
**Objectif** : Affiner les param√®tres pour des performances optimales

#### 7.1 - Param√®tres du filtre spatial

```bash
ros2 param set /traitement_cartesian_node spatial_filter_radius 2.0
ros2 param set /traitement_cartesian_node spatial_filter_sigma 0.8
```

Tester : 1.5m, 2.0m, 2.5m pour le rayon.

#### 7.2 - Param√®tres Hough

```bash
ros2 param set /hough_lines_node threshold 30
ros2 param set /hough_lines_node min_line_length 40
ros2 param set /hough_lines_node max_line_gap 15
```

#### 7.3 - Param√®tres de d√©tection rectangle

```bash
ros2 param set /rectangle_detector_node width_tolerance 0.4
ros2 param set /rectangle_detector_node height_tolerance 0.4
ros2 param set /rectangle_detector_node angle_tolerance 20.0
```

---

### ‚úÖ **√âTAPE 8 : Documentation et Nettoyage**
**Objectif** : Finaliser et documenter

#### 8.1 - Cr√©er fichiers de configuration YAML

**Fichier** : `ros2_bluerov/src/tracking/config/rectangle_detector_params.yaml`
```yaml
rectangle_detector_node:
  ros__parameters:
    enable_detection: true
    expected_cage_width: 1.0
    expected_cage_height: 1.5
    width_tolerance: 0.3
    height_tolerance: 0.3
    angle_tolerance: 15.0
    min_lines_required: 4
    use_tracked_position: true
```

#### 8.2 - Mettre √† jour le README

Documenter :
- Nouveau n≈ìud `rectangle_detector_node`
- Nouveau message `DetectedRectangle`
- Nouveau topic `/docking/tracking/detected_rectangle`
- Param√®tres de configuration

#### 8.3 - Ajouter des logs informatifs

Dans chaque n≈ìud, ajouter des logs pour faciliter le debug :
```python
self.get_logger().info(f'Rectangle d√©tect√©: {width:.2f}x{height:.2f}m, confiance={confidence:.2f}')
```

---

## üìä Checklist Finale

### Fonctionnalit√©s
- [ ] Filtre spatial gaussien op√©rationnel
- [ ] D√©tection Hough optimis√©e
- [ ] D√©tection de rectangle robuste
- [ ] Affichage du rectangle en temps r√©el
- [ ] Tous les launch files mis √† jour

### Tests
- [ ] Test avec sonar mock
- [ ] Test avec rosbag
- [ ] Test avec sonar r√©el
- [ ] Tests de robustesse (mouvement, rotation, etc.)

### Documentation
- [ ] README mis √† jour
- [ ] Fichiers YAML de configuration cr√©√©s
- [ ] Commentaires dans le code
- [ ] Ce plan archiv√© pour r√©f√©rence

---

## üîß D√©pannage Courant

### Probl√®me : Pas de rectangle d√©tect√©
- V√©rifier que Hough d√©tecte au moins 4 lignes : `ros2 topic echo /docking/tracking/detected_lines`
- Augmenter `num_lines` dans hough_lines_node
- R√©duire `threshold` dans hough_lines_node
- Augmenter les tol√©rances dans rectangle_detector

### Probl√®me : Rectangle instable (saute d'une frame √† l'autre)
- Filtrer temporellement les d√©tections (moyenne glissante)
- Augmenter la pond√©ration de `proximity_score`
- R√©duire `max_line_gap` dans Hough

### Probl√®me : Filtre spatial ne s'applique pas
- V√©rifier que `enable_spatial_filter` est √† `true`
- V√©rifier que le tracker publie : `ros2 topic echo /docking/tracking/tracked_object`
- V√©rifier les logs de `traitement_cartesian_node`

---

## üéì Concepts Cl√©s

### Filtre Gaussien Spatial
- **But** : Isoler la zone d'int√©r√™t (cage)
- **Formule** : `mask = exp(-(dist¬≤ / (2œÉ¬≤)))`
- **Effet** : Att√©nuation progressive (pas binaire)

### Transform√©e de Hough
- **But** : D√©tecter des lignes dans une image
- **Entr√©e** : Image binaire (Canny)
- **Sortie** : Lignes en coordonn√©es polaires (œÅ, Œ∏)

### D√©tection de Rectangle
- **M√©thode** : Intersection de lignes
- **Contraintes** : Dimensions attendues, parall√©lisme
- **Score** : Combinaison de pr√©cision dimensionnelle et confiance

---

**Temps estim√© total** : 6-8 heures (avec tests et ajustements)

**Ordre de priorit√©** :
1. √âtape 1 (filtre spatial) - **Critique**
2. √âtape 3 (d√©tection rectangle) - **Critique**
3. √âtape 4 (affichage) - **Importante**
4. √âtapes 2, 5, 6, 7 (optimisation/tests) - **Am√©lioration continue**
